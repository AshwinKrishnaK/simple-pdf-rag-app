SIMPLE RAG CHAT APP USING GROQ
This Streamlit application demonstrates a simple Retrieval-Augmented Generation (RAG) system for chat using Langchain libraries. The app allows you to upload a PDF document and then ask questions about its content.

Features
Upload and embed a PDF document.
Ask questions about the uploaded document.
Get answers generated by a large language model based on the context of the document and your question.
Requirements
Python 3.7+
Streamlit
Langchain
Langchain OpenAI
Langchain Groq
Langchain Community libraries (document_loaders, vectorstores)
dotenv
Installation
Install required libraries using pip:
Bash

pip install streamlit langchain langchain-openai langchain-groq langchain-community[vectorstores,document_loaders] python-dotenv
Create a .env file in your project directory and add your API keys:
OPENAI_API_KEY=<your_openai_api_key>
LANGCHAIN_API_KEY=<your_langchain_api_key>
GROQ_API_KEY=<your_groq_api_key>
Usage
Run the application using:
Bash

streamlit run app.py
Upload a PDF document.
Enter your question in the text box.
Click the "Ask Question" button (or a similar button you might implement).
The application will process your question and generate a response based on the uploaded document and your question.
Notes
This is a basic example and can be extended with functionalities like handling multiple documents or different question formats.
Make sure to replace <your_openai_api_key>, <your_langchain_api_key>, and <your_groq_api_key> with your actual API keys.
